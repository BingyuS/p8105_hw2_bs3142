---
title: "p8105_hw2_bs3142"
author: "Bingyu Sun"
date: "9/30/2018"
output: github_document
---

```{r setup and load library}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse) # load tidyverse library
library(readxl)    # load readxl library

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)       # set graph format

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

### Problem 1    NYC Transit Data


#### Section 1: Data Manipulation

**Data cleaning**

  * Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance
  * Convert the entry variable from character to a logical variable 
    
```{r clean_my_nyc_transit_data}
my_nyc_transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  # import nyc transit data
  janitor::clean_names() %>% # clean variable names
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  # specify variables
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) # Convert entry variable to logical variable
```


**Summary**

1. Variables in the dataset

    * The dataset contains information about NYC transit, like station location, routes served in each station, station entrance type, vending, and ADA compliance. 
  
2. Data cleaning steps

    * I created a data frame for cleaning raw NYC Transit data. The dataset is imported using a relative path and names are cleaned by janitor function. Specific variables in the dateset are selected. Furthermore, the entry variable has been converted to a logical vector. The resulting dataset consists of **`r nrow(my_nyc_transit_data)`** rows by **`r ncol(my_nyc_transit_data)`** columns.
  
3. Data assessment

    * The data is untidy. There are 11 columns of route numbers that should be organized into a single column under route number with a corresponding column for route names.



#### Section 2: Data features

**1. How many distinct stations are there?**

```{r Distinct stations: both by line and by name}
distinct_my_nyc_transit_data = 
  my_nyc_transit_data %>%
  distinct(line, station_name, .keep_all = TRUE) 
# make stations distinct

nrow(distinct_my_nyc_transit_data) # count number of rows
```

There are **465** distinct train stations.

**2. How many stations are ADA compliant?**

```{r Number of stations that are ADA compliant}
distinct_my_nyc_transit_data %>%
  filter(ada == "TRUE") %>% # get ADA compliant stations
  count 
```

**84** of the 465 stations are ADA compliant.

**3. What proportion of station entrances / exits without vending allow entrance?**

```{r Proportion of station without vending allow entrance}
nrow(filter(my_nyc_transit_data, vending == "NO", entry == "TRUE")) / nrow(filter(my_nyc_transit_data, vending == "NO")) # calc proportion
```

**37.7%** of the station without vending allow entrance.



#### Section 3: Reformat data


* Transform route number and route name to distinct variables 

```{r reformat my nyc transit data}
tidy_my_nyc_transit_data =
  my_nyc_transit_data %>%
  gather(key = "route_number", value = "route_name", route1:route11) %>% 
  # reformat route1 to route11 into two columns
  distinct(line, station_name, .keep_all = TRUE) %>%
  filter(route_name == "A") %>% # get stations that serve train A
  filter(ada == "TRUE") # ADA compliant stations that serve train A
```

**How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?**

* There are **60** distinct stations serve Train A, and **17** of them are ADA compliant.


### Problem 2 Mr. Trash Wheel

#### Section 1: Data Manipulation of Mr. Trash Wheel sheet

**Data Cleaning**

* specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell_cols() function)
* use reasonable variable names
* omit rows that do not include dumpster-specific data
* rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r tidy my_wheel data}
my_wheel_data =
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = cell_cols("Dumpster:Homes Powered")) %>% # import wheel data
  janitor::clean_names() %>% # clean names
  select(-x_1) %>% # remove notes
  filter(!is.na(dumpster)) %>% # remove rows without dumpster info
  mutate(sports_balls = as.integer(sports_balls)) # round values of sports balls to integers
```

#### Section 2: Data Manipulation of prcp 2016 & 2017

**Data Cleaning**

* Omit rows without precipitation data and add a variable year.
* Combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

Prcp_2017:

```{r tidy prcp_2017}
my_prcp_2017_data = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, skip = 1) %>% # import 2017 precipitation data
  janitor::clean_names() %>% # clean names
  rename(precipitation_in = total) %>% # rename a column
  mutate(year = "2017") %>% # add a column showing year
  filter(!is.na(month), !is.na(precipitation_in)) # filter out NA
```

Prcp_2016:

```{r tidy prcp_2016}
my_prcp_2016_data =
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, skip = 1) %>% # import 2016 precipitation data
  janitor::clean_names() %>% # clean names
  rename(precipitation_in = total) %>% # rename a column
  mutate(year = "2016") %>% # add a column showing year
  filter(!is.na(month), !is.na(precipitation_in)) # filter out NA
```

Prcp 2016 & 2017:

```{r combined 2016 and 2017 prcp}
my_combined_prcp_data =
  bind_rows(my_prcp_2016_data, my_prcp_2017_data) %>% 
  # combine 2016 and 2017 data
  mutate(month = month.name[month])
  # change month to month name
```

**Summary**

**1. Mr. Trash Wheel**

The dataset consists of **`r nrow(my_wheel_data)`** rows by **`r ncol(my_wheel_data)`** columns. There are **`r nrow(my_wheel_data)`** dumpsters recorded from year 2014 to 2018. Information like date, trash amount, and types are included. The median number of sports balls in a dumpster in 2016 was **`r median(na.omit(cbind(my_wheel_data$sports_balls[my_wheel_data$year == 2016])))`**.

**2. Precipitation 2017**

The dataset consists of `r nrow(my_prcp_2017_data)` observations of monthly amount of precipitation in 2017. The total precipitation in 2017 was **`r sum(my_prcp_2017_data$precipitation_in)`** inches.

**3. Precipitation 2016**

The dataset consists of `r nrow(my_prcp_2016_data)` observations of monthly amount of precipitation in 2016. The total precipitation in 2016 was **`r sum(my_prcp_2016_data$precipitation_in)`** inches.

**4. Precipitation 2016 & 2017**

The dataset is a combined dataset for 2016 and 2017 precipitation data. It consists of **`r nrow(my_combined_prcp_data)`** observations, one per month. One difference in the dataset is that the numeric monthes are converted to character variables.

### Problem 3

#### Section 1: Data Import

```{r import BRFSS data}
library(p8105.datasets)
data(brfss_smart2010) # import BRFSS data
```

#### Section 2: Data Manipulation

* Format the data to use appropriate variable names
* Focus on the “Overall Health” topic
* Exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
* Structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)
* Create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

```{r clean my_brfss_data}
my_brfss_data = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>% 
  # select rows based on overall health
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>% 
  # reformat response
  janitor::clean_names() %>%
  mutate(prop_excellent_and_very_good = (excellent + very_good)) # add a column of proportion for excellent and very good
```

**Summary**

**1. How many unique locations are included in the dataset? Is every state represented? What state is observed the most?**

The dataset contains **`r length(unique(my_brfss_data$locationdesc))`** unique locations, in **`r length(unique(my_brfss_data$locationabbr))`** states. Therefore, every state is represented. **`r names(which.max(table(my_brfss_data$locationabbr)))`** (New Jersey) state is observed the most.

**2. In 2002, what is the median of the “Excellent” response value?**

In 2002, the median of the "Excellent" response value is **`r median(na.omit(cbind(my_brfss_data$excellent[my_brfss_data$year == 2002])))`**.


#### Section 3: Plots

1. **Histogram** of “Excellent” response values in the year 2002

```{r Histogram of Excellent in 2002}
my_brfss_data %>%
  select(year, excellent) %>%
  filter(year == "2002") %>%
  # retain only 2002 data
  ggplot(aes(x = excellent)) +
  geom_histogram() +
  labs(x = "Excellent",
       title = "Histogram of Excellent response values in 2002") # plot histogram
```

2. **Scatterplot** showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010

```{r Scatterplot of excellent response proportion in NY country and Queens County from 2002-2010}
my_brfss_data %>%
  select(year, locationdesc, excellent) %>%
  filter(locationdesc %in% c("NY - New York County", "NY - Queens County")) %>%
  # retain New York County and Queens County info
  ggplot(aes(x = year, y = excellent, color = locationdesc)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Scatterplot of Excellent response proportion in New York County and Queens Country in 2002 to 2010") # plot scatterplot
```

